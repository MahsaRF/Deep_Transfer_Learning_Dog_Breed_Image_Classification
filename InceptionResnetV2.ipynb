{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InceptionResnetV2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM0c2Fk9L10Yk4AtApuhanr"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "4dWSRo0go4pR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import os.path\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras.models import Model\n",
        "from tensorflow.python.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.python.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import Sequence\n",
        "import keras.models\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams"
      ],
      "metadata": {
        "id": "ZrCwLKHOprGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Exploration"
      ],
      "metadata": {
        "id": "CyMdqUUCpwUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "breed_list = os.listdir(\"images/\")\n",
        "number_of_used_breed =40\n",
        "from PIL import Image\n",
        "breed_in_use = 1\n"
      ],
      "metadata": {
        "id": "Wmh1FXp6p3fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating training and testing dataset"
      ],
      "metadata": {
        "id": "pY01rTsEqAQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('Mydata',exist_ok= True)\n",
        "os.makedirs('Mydata/Train',exist_ok= True)\n",
        "os.makedirs('Mydata/Valid',exist_ok= True)\n",
        "for breed in breed_list:\n",
        "    os.makedirs('Mydata/Train/' + breed,exist_ok= True)\n",
        "    os.makedirs('Mydata/Valid/' + breed,exist_ok= True)\n",
        "    if breed_in_use == number_of_used_breed:\n",
        "        break\n",
        "    breed_in_use = breed_in_use+1\n",
        "print('Created {} folders to store Training images of the different breeds.'.format(len(os.listdir('Mydata/Train'))))\n",
        "print('Created {} folders to store Validation images of the different breeds.'.format(len(os.listdir('Mydata/Valid'))))\n",
        "\n",
        "validation_to_training_ratio = .1\n",
        "breed_in_use = 1\n",
        "for breed in os.listdir('Mydata/Train'):\n",
        "    cpt = sum([len(files) for r, d, files in os.walk('images/{}/'.format(breed))])\n",
        "    validation = (int)(cpt * validation_to_training_ratio)\n",
        "    index = 0\n",
        "    for file in os.listdir('images/{}'.format(breed)):\n",
        "        img = Image.open('images/{}/{}'.format(breed, file))\n",
        "        img = img.convert('RGB')        \n",
        "        if index<validation:\n",
        "            img.save('Mydata/Valid/' + breed + '/' + file + '.jpg')\n",
        "        else:\n",
        "            img.save('Mydata/Train/' + breed + '/' + file + '.jpg')\n",
        "        index = index +1\n",
        "    if breed_in_use == number_of_used_breed:\n",
        "        break    \n",
        "    breed_in_use = breed_in_use+1\n",
        "\n",
        "train_dir = 'Mydata/Train'\n",
        "validation_dir = 'Mydata/Valid'\n",
        "train_batchsize = 50\n",
        "val_batchsize = 10"
      ],
      "metadata": {
        "id": "PdXFAd24qI7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Custom Dataset"
      ],
      "metadata": {
        "id": "o2ki3OFvrIf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 50 using train_datagen generator\n",
        "train_batches  = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = train_batchsize,\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 10 using test_datagen generator\n",
        "valid_batches =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = val_batchsize,\n",
        "                                                          class_mode  = 'categorical',\n",
        "                                                          target_size = (150, 150),\n",
        "                                                          shuffle=False)\n",
        "\n",
        "train_sample = sum([len(files) for r, d, files in os.walk(train_dir)])\n",
        "validation_sample = sum([len(files) for r, d, files in os.walk(validation_dir)])\n",
        "\n",
        "print('****************')\n",
        "#cls_str = []\n",
        "for cls, idx in train_batches.class_indices.items():\n",
        "    #cls_str.append(cls)\n",
        "    print('Class #{} = {}'.format(idx, cls))\n",
        "    #print(cls)\n",
        "#print(cls_str)    \n",
        "print('****************')"
      ],
      "metadata": {
        "id": "okJBouunrMCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Network Architecture\n",
        "\n",
        "Inception V3 pre-trained model\n"
      ],
      "metadata": {
        "id": "218tjrJft_8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE    = (150, 150)\n",
        "net = InceptionResNetV2(include_top=False,\n",
        "                        input_tensor=None,\n",
        "                        input_shape=(IMAGE_SIZE[0],IMAGE_SIZE[1],3))\n",
        "for layer in net.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "net.summary()\n",
        "\n",
        "last_layer_InceptionResV2 = net.get_layer('block8_9')\n",
        "\n",
        "print('InceptionResV2 last layer output shape: ', last_layer_InceptionResV2.output_shape)\n",
        "InceptionResV2_last_output = last_layer_InceptionResV2.output\n",
        "\n",
        "\n",
        "x_InceptionResV2 = layers.Flatten()(InceptionResV2_last_output)\n",
        "\n",
        "# Add a fully connected layer with 512 hidden units and sigmoid activation\n",
        "x_InceptionResV2 = layers.Dense(512, activation='sigmoid')(x_InceptionResV2)\n",
        "\n",
        "# Add a dropout rate of 0.2\n",
        "x_InceptionResV2 = layers.Dropout(0.2)(x_InceptionResV2)                  \n",
        "\n",
        "# Add a final sigmoid layer for classification\n",
        "x_InceptionResV2 = layers.Dense  (number_of_used_breed, activation='softmax')(x_InceptionResV2)           \n",
        "InceptionResV2_model = Model( net.input, x_InceptionResV2) \n",
        "InceptionResV2_model.compile(optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False), \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "InceptionResV2_model.summary()\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('acc')>0.95):\n",
        "            print('/nTraining will stop as we have reached 95% of acc')\n",
        "            self.model.stop_training=True\n",
        "        \n",
        "callback=myCallback()"
      ],
      "metadata": {
        "id": "TQJ1eSMOuCcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "UyDASHzI7RSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_InceptionResV2 = InceptionResV2_model.fit_generator(\n",
        "            train_batches,\n",
        "            validation_data = valid_batches,\n",
        "            steps_per_epoch = train_sample // train_batchsize,\n",
        "            epochs = 20,\n",
        "            validation_steps = validation_sample//val_batchsize,\n",
        "            verbose = 2,\n",
        "            callbacks=[callback]\n",
        ")\n",
        "acc = history_InceptionResV2.history['acc']\n",
        "val_acc = history_InceptionResV2.history['val_acc']\n",
        "loss = history_InceptionResV2.history['loss']\n",
        "val_loss = history_InceptionResV2.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))"
      ],
      "metadata": {
        "id": "75Co9qu18dI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting history \n",
        "\n",
        "Accuracy v/s Epochs plot"
      ],
      "metadata": {
        "id": "d9DRXSyS8yZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy_InceptionResnetV2')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_Nd-NEnZ-Id8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction"
      ],
      "metadata": {
        "id": "Wn-RQFVP-Ok4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-hsIxgWhniB"
      },
      "outputs": [],
      "source": [
        "test_steps_per_epoch = numpy.math.ceil(validation_sample / val_batchsize)\n",
        "predictions = InceptionResV2_model.predict_generator(valid_batches, steps=test_steps_per_epoch)\n",
        "# Get most likely class\n",
        "predicted_classes = numpy.argmax(predictions, axis=1)\n",
        "\n",
        "l=list(valid_batches.class_indices.keys())\n",
        "split_list =[i.split() for i in l]\n",
        "class_labels=[]\n",
        "for i in (range(len(split_list))):\n",
        "    class_labels.append(split_list[i][0].split(\"-\",1)[1])\n",
        "\n",
        "true_classes = valid_batches.classes\n",
        "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "print(report)\n",
        "\n",
        "cm= confusion_matrix(true_classes,predicted_classes,labels=np.unique(true_classes))\n",
        "print(cm)\n",
        "\n",
        "rcParams['figure.figsize'] = 10, 10\n",
        "plt.style.use('ggplot')\n",
        "fig, ax = plt.subplots(figsize=(18, 18))\n",
        "_ = sns.heatmap(cm, ax=ax, yticklabels=class_labels, xticklabels=class_labels, robust=True)\n",
        "ax.set_title('Confusion matrix')\n",
        "#set ticklabels rotation\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation = 90, fontsize = 10)\n",
        "ax.set_yticklabels(ax.get_yticklabels(), rotation = 0, fontsize = 10)\n",
        "\n"
      ]
    }
  ]
}